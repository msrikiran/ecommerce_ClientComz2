{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Market Feature Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Client ComZ is an ecommerce company. The company wants to focus on targeting the right customers  with the right products to increase overall revenue and conversion rate.\n",
    "\n",
    "- To target the right customers with the right products, they need to build an ML model for marketing based on user interaction with products in the past like number of views,  most viewed product, number of activities of user, vintage of user and others. \n",
    "\n",
    "- ComZ has contacted the Data Science and Engineering team to use this information to fuel the personalized advertisements, email marketing campaigns, or special offers on the landing and category pages of the company's website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Visitor Log Data** – It is a browsing log data of all the visitors and the users. This table contains the following information:\n",
    "\n",
    "- *WebClientID*:\n",
    "Unique ID of browser for every system. (If a visitor is using multiple browsers on a system like Chrome, Safari, then there would be a different web clientid for each browser). The ID remains consistent unless the user clears their cookie.\n",
    "\n",
    "- *VisitDateTime*:\n",
    "Date and time of visit. There are two different formats for DateTime. \n",
    "One is in datetime format “2018-05-07 04:28:45.970”\n",
    "Another one is in unix datetime format “1527051855673000000”\n",
    "\n",
    "- *ProductID*:\n",
    "Unique ID of product browsed/ clicked by the visitor\n",
    "\n",
    "- *UserID*:     \n",
    "Unique ID of the registered user. As expected, this is available for registered users only, not for all visitors. \n",
    "\n",
    "- *Activity*:\n",
    "Type of activity can be browsing (pageload) or clicking a product\n",
    "\n",
    "- *Browser*:\n",
    "Browser used by the visitor\n",
    "\n",
    "- *OS*:\n",
    "Operating System of the system used by the visitor\n",
    "\n",
    "- *City*:\n",
    "City of the visitor\n",
    "\n",
    "- *Country*:\n",
    "Country of the visitor\n",
    "\n",
    "\n",
    "**2. User Data** – It has registered user information like signup date and segment.\n",
    "\n",
    "- *UserID*:\n",
    "Unique ID of the registered user.\n",
    "\n",
    "- *Signup Date*:\n",
    "Date of registration for the user\n",
    "\n",
    "- *User Segment*:\n",
    "User Segment (A/B/C) created based on historical engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from datetime import datetime, timezone\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# setting directory and pandas max rows/cols\n",
    "os.chdir(\"D:\\\\EDA\\\\JobAThon\\\\ecommerce\")\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data files\n",
    "userTable_data = pd.read_csv(\"userTable.csv\")\n",
    "VisitorLogs_data = pd.read_csv(\"VisitorLogsData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of rows and columns in the userTable are:(34050, 3) \n",
      "the number of rows and columns in the VisitorLogs_data are:(6588000, 9) \n"
     ]
    }
   ],
   "source": [
    "#looking rows and columns are in both files\n",
    "print(\"the number of rows and columns in the userTable are:{} \".format(userTable_data.shape))\n",
    "print(\"the number of rows and columns in the VisitorLogs_data are:{} \".format(VisitorLogs_data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    UserID                       Signup Date User Segment\n",
      "0  U133159  2018-04-14 07:01:16.202607+00:00            C\n",
      "1  U129368  2017-12-02 09:38:41.584270+00:00            B\n",
      "\n",
      "\n",
      "************************************************************\n",
      "     webClientID            VisitDateTime ProductID UserID Activity  \\\n",
      "0  WI10000050298  2018-05-07 04:28:45.970  pr100631    NaN      NaN   \n",
      "1  WI10000025922  2018-05-13 07:26:04.964  pr100707    NaN      NaN   \n",
      "\n",
      "         Browser       OS     City Country  \n",
      "0  Chrome Mobile  Android  Chennai   India  \n",
      "1         Chrome  Windows      NaN  Taiwan  \n"
     ]
    }
   ],
   "source": [
    "#looking first 2 rows in both files\n",
    "print(userTable_data.head(2))\n",
    "print(\"\\n\")\n",
    "print(\"******\"*10)\n",
    "print(VisitorLogs_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# userTable datetime\n",
    "userTable_data[\"Signup Date\"] = pd.to_datetime(userTable_data[\"Signup Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2018-04-14 07:01:16.202607+00:00\n",
       "1   2017-12-02 09:38:41.584270+00:00\n",
       "2          2013-03-19 11:38:55+00:00\n",
       "3   2018-01-18 08:29:51.627954+00:00\n",
       "4   2018-03-27 08:05:28.806800+00:00\n",
       "Name: Signup Date, dtype: datetime64[ns, UTC]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userTable_data[\"Signup Date\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visitorlogsData converting to uppercase\n",
    "VisitorLogs_data.webClientID = VisitorLogs_data.webClientID.str.upper()\n",
    "VisitorLogs_data.ProductID = VisitorLogs_data.ProductID.str.upper()\n",
    "VisitorLogs_data.UserID = VisitorLogs_data.UserID.str.upper()\n",
    "VisitorLogs_data.Activity = VisitorLogs_data.Activity.str.upper()\n",
    "VisitorLogs_data.Browser = VisitorLogs_data.Browser.str.upper()\n",
    "VisitorLogs_data.OS = VisitorLogs_data.OS.str.upper()\n",
    "VisitorLogs_data.City = VisitorLogs_data.City.str.upper()\n",
    "VisitorLogs_data.Country = VisitorLogs_data.Country.str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VisitDateTime - separating into unix vs non-unix dates\n",
    "\n",
    "VisitorLogs_data['date_time_format'] = VisitorLogs_data['VisitDateTime'].str.isdigit().fillna(False)\n",
    "\n",
    "date_time_format1 = VisitorLogs_data[VisitorLogs_data['date_time_format']==True]\n",
    "date_time_format2 = VisitorLogs_data[VisitorLogs_data['date_time_format']==False]\n",
    "\n",
    "date_time_format1.VisitDateTime = pd.to_numeric(date_time_format1.VisitDateTime)\n",
    "date_time_format1['temp_VisitDateTime'] = (date_time_format1.VisitDateTime/1000000)\n",
    "date_time_format1['temp_VisitDateTime'] = date_time_format1['temp_VisitDateTime'].apply(np.int64)\n",
    "date_time_format1['VisitDateTime'] =  pd.to_datetime(date_time_format1['temp_VisitDateTime'], unit='ms')\n",
    "date_time_format1 = date_time_format1.drop(columns = 'temp_VisitDateTime')\n",
    "\n",
    "date_time_format2.VisitDateTime = pd.to_datetime(date_time_format2.VisitDateTime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## appending converted datetimes dataframes\n",
    "new_VLogsData = date_time_format1.append(date_time_format2)\n",
    "new_VLogsData = new_VLogsData.drop(columns = 'date_time_format')\n",
    "new_VLogsData['date'] = pd.DatetimeIndex(new_VLogsData.VisitDateTime).date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## missing value treatments / imputations for Activity and ProductID\n",
    "new_VLogsData = new_VLogsData.sort_values(['UserID','webClientID','VisitDateTime'])\n",
    "\n",
    "new_VLogsData['oldProductID'] = new_VLogsData.groupby(['UserID','date'])['ProductID'].shift(1)\n",
    "new_VLogsData['priorProductID'] = new_VLogsData.groupby(['UserID'])['ProductID'].shift(1)\n",
    "new_VLogsData['nextProductID'] = new_VLogsData.groupby(['UserID'])['ProductID'].shift(-1)\n",
    "\n",
    "new_VLogsData['newActivity'] = np.where(new_VLogsData['ProductID']==new_VLogsData['oldProductID'],'CLICK','PAGELOAD')\n",
    "new_VLogsData['Activity'] = np.where(new_VLogsData['Activity'].notnull(),new_VLogsData['Activity'],new_VLogsData['newActivity'])\n",
    "\n",
    "new_VLogsData['newProductID'] = np.where(new_VLogsData['Activity']=='CLICK',new_VLogsData['priorProductID'],new_VLogsData['nextProductID'])\n",
    "new_VLogsData['ProductID'] = np.where(new_VLogsData['ProductID'].notnull(),new_VLogsData['ProductID'],new_VLogsData['newProductID'])\n",
    "\n",
    "#Null values are filled with forward filling and backward filling \n",
    "new_VLogsData['ProductID'] = np.where(new_VLogsData['ProductID'].notnull(),new_VLogsData['ProductID'],new_VLogsData['ProductID'].ffill().bfill())\n",
    "\n",
    "new_VLogsData['priordate'] = new_VLogsData.groupby(['UserID'])['date'].shift(1)\n",
    "new_VLogsData['nextdate'] = new_VLogsData.groupby(['UserID'])['date'].shift(-1)\n",
    "new_VLogsData = new_VLogsData.sort_values(['UserID','webClientID','ProductID'])\n",
    "new_VLogsData['VisitDateTime'] = np.where(new_VLogsData['VisitDateTime'].notnull(),new_VLogsData['VisitDateTime'],new_VLogsData['VisitDateTime'].ffill().bfill())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping duplicate records by user/system and time\n",
    "\n",
    "new_VLogsData = new_VLogsData.drop_duplicates(subset = ['UserID', 'webClientID','VisitDateTime'], keep = 'first').reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation\n",
    "\n",
    "last_7_days = new_VLogsData[new_VLogsData['VisitDateTime']>=(max(new_VLogsData['VisitDateTime'])-pd.to_timedelta(7, unit='d'))]\n",
    "last_15_days = new_VLogsData[new_VLogsData['VisitDateTime']>=(max(new_VLogsData['VisitDateTime'])-pd.to_timedelta(15, unit='d'))]\n",
    "\n",
    "# No_of_days_Visited_7_Days\n",
    "# How many days a user was active on platform in the last 7 days - count distinct visitdatetime by userid when webclientid = 1\n",
    "no_of_visits_7_days = pd.DataFrame(last_7_days.groupby('UserID').date.nunique())\n",
    "no_of_visits_7_days = no_of_visits_7_days.reset_index()\n",
    "no_of_visits_7_days = no_of_visits_7_days.rename(columns = {'date':'No_of_days_Visited_7_Days'})\n",
    "\n",
    "# Clicks_last_7_days - Count of Clicks in the last 7 days  by the user\n",
    "click_counts = pd.DataFrame(last_7_days[last_7_days['Activity']=='CLICK'].groupby('UserID').Activity.count())\n",
    "click_counts = click_counts.reset_index()\n",
    "click_counts = click_counts.rename(columns = {'Activity':'Clicks_last_7_days'})\n",
    "\n",
    "# Pageloads_last_7_days - Count of pageloads in the last 7 days  by the user\n",
    "pageload_counts = pd.DataFrame(last_7_days[last_7_days['Activity']=='PAGELOAD'].groupby('UserID').Activity.count())\n",
    "pageload_counts = pageload_counts.reset_index()\n",
    "pageload_counts = pageload_counts.rename(columns = {'Activity':'Pageloads_last_7_days'})\n",
    "\n",
    "# No_Of_Products_Viewed_15_Days - Number of Products viewed by the user in the last 15 days\n",
    "no_prod_15d = pd.DataFrame(last_15_days.groupby('UserID').ProductID.nunique())\n",
    "no_prod_15d = no_prod_15d.reset_index()\n",
    "no_prod_15d = no_prod_15d.rename(columns = {'ProductID':'No_Of_Products_Viewed_15_Days'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most frequently viewed (page loads) product by the user in the last 15 days. If there are multiple products that have \n",
    "# a similar number of page loads then , consider the recent one. If a user has not viewed any product in the last 15 days \n",
    "# then put it as Product101. \n",
    "\n",
    "most_view_prod_15d = last_15_days[last_15_days['Activity']=='PAGELOAD'].groupby(['UserID','ProductID']).\\\n",
    "                                agg({'Activity':'count','VisitDateTime':'max'})\n",
    "most_view_prod_15d = most_view_prod_15d.reset_index()\n",
    "\n",
    "most_view_prod_15d_grp = most_view_prod_15d.sort_values(['Activity','VisitDateTime'], ascending=False).drop_duplicates(['UserID'])\n",
    "most_view_prod_15d_grp =most_view_prod_15d_grp.sort_values('UserID')\n",
    "\n",
    "most_view_prod = most_view_prod_15d_grp[['UserID','ProductID']]\n",
    "most_view_prod = most_view_prod.rename(columns = {'ProductID':'Most_Viewed_product_15_Days'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as per the datset given time is calculated from 2018-05-27\n",
    "#User vintage is today - signup date (Vintage (In Days) of the user as of today)\n",
    "user_vintage_days = userTable_data.copy()\n",
    "user_vintage_days['today'] = pd.to_datetime('2018-05-27',utc=True)\n",
    "user_vintage_days['User_Vintage'] = (user_vintage_days['today']-user_vintage_days['Signup Date']).dt.days\n",
    "user_vintage_days= user_vintage_days[['UserID','User_Vintage']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most_Active_OS - Most Frequently used OS by user\n",
    "most_active_os_data = new_VLogsData.groupby(['UserID','OS']).\\\n",
    "                                agg({'webClientID':'count',\\\n",
    "                                    'VisitDateTime':'max'})\n",
    "most_active_os_data = most_active_os_data.sort_values(by = ['UserID']).reset_index()\n",
    "\n",
    "most_active_os_data_grp = most_active_os_data.sort_values(['webClientID','VisitDateTime'], ascending=False).drop_duplicates(['UserID'])\n",
    "\n",
    "most_active_os_df = most_active_os_data_grp[['UserID','OS']]\n",
    "most_active_os_df = most_active_os_df.rename(columns = {'OS':'Most_Active_OS'})\n",
    "most_active_os_df = most_active_os_df.sort_values('UserID')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recently_Viewed_Product - Most recently viewed (page loads) product by the user. If a user has not viewed any product then put it as Product101.\n",
    "\n",
    "recent_product = new_VLogsData[(new_VLogsData['Activity']=='PAGELOAD') & (pd.notnull(new_VLogsData['ProductID']))]\n",
    "recent_product = recent_product[['UserID','ProductID','VisitDateTime']]\n",
    "\n",
    "recent_product_grp = recent_product.sort_values('VisitDateTime', ascending=False).drop_duplicates(['UserID'])\n",
    "recent_product_grp = recent_product_grp.sort_values('UserID')\n",
    "recent_product_grp = recent_product_grp[['UserID','ProductID']]\n",
    "recent_product_grp = recent_product_grp.rename(columns = {'ProductID':'Recently_Viewed_Product'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging total data\n",
    "\n",
    "main_data = userTable_data[['UserID']]\n",
    "\n",
    "join_newVLogsData = main_data\\\n",
    "            .merge(no_of_visits_7_days, how='left', on = 'UserID')\\\n",
    "            .merge(no_prod_15d, how='left', on = 'UserID')\\\n",
    "            .merge(user_vintage_days, how='left', on = 'UserID')\\\n",
    "            .merge(most_view_prod, how='left', on = 'UserID')\\\n",
    "            .merge(most_active_os_df, how='left', on = 'UserID')\\\n",
    "            .merge(recent_product_grp, how='left', on = 'UserID')\\\n",
    "            .merge(pageload_counts, how='left', on = 'UserID')\\\n",
    "            .merge(click_counts, how='left', on = 'UserID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing value treatment by adding Product101\n",
    "\n",
    "join_newVLogsData['No_of_days_Visited_7_Days'] = join_newVLogsData['No_of_days_Visited_7_Days'].replace(np.nan, 0)\n",
    "join_newVLogsData['No_Of_Products_Viewed_15_Days'] = join_newVLogsData['No_Of_Products_Viewed_15_Days'].replace(np.nan, 0)\n",
    "join_newVLogsData['User_Vintage'] = join_newVLogsData['User_Vintage'].replace(np.nan, 0)\n",
    "join_newVLogsData['Pageloads_last_7_days'] = join_newVLogsData['Pageloads_last_7_days'].replace(np.nan, 0)\n",
    "join_newVLogsData['Clicks_last_7_days'] = join_newVLogsData['Clicks_last_7_days'].replace(np.nan, 0)\n",
    "join_newVLogsData['Most_Viewed_product_15_Days'] = join_newVLogsData['Most_Viewed_product_15_Days'].replace(np.nan, 'PRODUCT101')\n",
    "join_newVLogsData['Recently_Viewed_Product'] = join_newVLogsData['Recently_Viewed_Product'].replace(np.nan, 'PRODUCT101')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing datatypes to int type\n",
    "\n",
    "join_newVLogsData['No_of_days_Visited_7_Days'] = join_newVLogsData['No_of_days_Visited_7_Days'].astype(int)\n",
    "join_newVLogsData['No_Of_Products_Viewed_15_Days'] = join_newVLogsData['No_Of_Products_Viewed_15_Days'].astype(int)\n",
    "join_newVLogsData['User_Vintage'] = join_newVLogsData['User_Vintage'].astype(int)\n",
    "join_newVLogsData['Pageloads_last_7_days'] = join_newVLogsData['Pageloads_last_7_days'].astype(int)\n",
    "join_newVLogsData['Clicks_last_7_days'] = join_newVLogsData['Clicks_last_7_days'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting data with based on UserID\n",
    "join_newVLogsData.sort_values('UserID',inplace=True)\n",
    "\n",
    "# exporting final to csv\n",
    "join_newVLogsData.to_csv(\"my_submission_file.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
